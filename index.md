---
title: My page
layout: default
---

## Instructors

<div class="instructor">
  <a href="https://people.eecs.berkeley.edu/~trevor/">
  <div class="instructorphoto"><img src="trevordarrell.jpg"></div>
  <div>Trevor Darrell</div>
  </a>
</div>
<div class="instructor">
  <a href="https://people.eecs.berkeley.edu/~dawnsong/">
  <div class="instructorphoto"><img src="dawnsong.jpg"></div>
  <div>Dawn Song
  <a href="https://twitter.com/dawnsongtweets"><img src="twitter.jpg"></a>
  </div>
  </a>

</div>

## Teaching Assistants

<div class="instructor">
  <a href="http://www.robertnishihara.com">
  <div class="instructorphoto"><img src="robertnishihara.jpg"></div>
  <div>Robert Nishihara
  <a href="https://twitter.com/robertnishihara"><img src="twitter.jpg"></a>
  </div>
  </a>
</div>

## Office Hours

Robert Nishihara: By appointment

## Lectures

**Time**: Monday 1 - 2:30pm

**Location**: Soda 306

## Piazza

Course announcements will be announced through Piazza. If you are in the class,
[**sign up on Piazza**](https://piazza.com/class/j8waviey9h55w8).

For more information about deep learning at Berkeley, sign up for the
[talk announcement mailing list](https://groups.google.com/forum/#!forum/berkeley-deep-learning).


## Syllabus

<table style="table-layout: fixed; font-size: 88%;">
  <thead>
    <tr>
      <th style="width: 5%;">Date</th>
      <th style="width: 17%;">Speaker</th>
      <th style="width: 50%;">Readings</th>
      <th style="width: 15%;">Talk</th>
      <th style="width: 15%;">Deadlines</th>
    </tr>
  </thead>
  <tbody>

    <tr>
      <td>01/22</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#stefano-soatto-the-emergence-theory-of-deep-learning">Stefano Soatto</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1706.01350">Emergence of Invariance and Disentanglement in Deep Representations</a> </li>
      <li><a href="https://arxiv.org/abs/1710.11029">Stochastic Gradient Descent Performs Variational Inference, Converges to Limit Cycles for Deep Networks</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://en.wikipedia.org/wiki/Information_bottleneck_method">Information Bottleneck Method</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#stefano-soatto-the-emergence-theory-of-deep-learning">The Emergence Theory of Deep Learning</a></td>
      <td></td>
    </tr>

    <tr>
      <td>01/29</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#alison-gopnik-what-4-year-olds-can-do-and-ai-cannot-yet">Alison Gopnik</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="http://www.pnas.org/content/114/30/7892">Changes in cognitive flexibility and hypothesis search across human life history from childhood to adolescence to adulthood</a></li>
      <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422420/">Reconstructing constructivism: Causal models, Bayesian learning mechanisms and the theory theory</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://cocosci.berkeley.edu/tom/papers/LabPublications/GopnicketalYoungLearners.pdf">When Younger Learners Can Be Better (or at Least More Open-Minded) Than Older Ones</a></li>
      <li><a href="https://cocosci.berkeley.edu/Liz/BonawitzTrends2014.pdf">Probabilistic models, learning algorithms, and response variability: sampling in cognitive development</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#alison-gopnik-what-4-year-olds-can-do-and-ai-cannot-yet">What 4 year olds can do and AI canâ€™t (yet)</a></td>
      <td></td>
    </tr>

    <tr>
      <td>02/05</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#mike-lewis-deal-or-no-deal-end-to-end-learning-for-negotiation-dialogues">Mike Lewis</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1706.05125">Deal or No Deal? End-to-End Learning for Negotiation Dialogues</a></li>
      <li><a href="https://arxiv.org/abs/1712.05846">Hierarchical Text Generation and Planning for Strategic Dialogue</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1703.06585">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#mike-lewis-deal-or-no-deal-end-to-end-learning-for-negotiation-dialogues">Deal or No Deal? End-to-End Learning for Negotiation Dialogues</a></td>
      <td></td>
    </tr>

    <tr>
      <td>02/12</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#kevin-murphy-probabilistic-models-for-vision-and-language">Kevin Murphy</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1612.00370">Improved Image Captioning via Policy Gradient optimization of SPIDEr</a></li>
      <li><a href="https://arxiv.org/abs/1705.10762">Generative Models of Visually Grounded Imagination</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="http://arxiv.org/abs/1612.00563">Self-critical Sequence Training for Image Captioning</a></li>
      <li><a href="http://arxiv.org/abs/1707.03389">SCAN: Learning Abstract Hierarchical Compositional Visual Concepts</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#kevin-murphy-probabilistic-models-for-vision-and-language">Probabilistic models for vision and language</a></td>
      <td>Final Project Proposal Due</td>
    </tr>

    <tr>
      <td>02/19</td>
      <td>President's Day</td>
      <td>
      </td>
      <td></td>
      <td></td>
    </tr>

    <tr>
      <td>02/26</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#thomas-funkhouser-data-driven-methods-for-matching-labeling-and-synthesizing-3d-shapes">Thomas Funkhouser</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1603.08182">3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions</a></li>
      <li><a href="https://arxiv.org/abs/1706.05170">Interactive 3D Modeling with a Generative Adversarial Network</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1611.08974">Semantic Scene Completion from a Single Depth Image</a></li>
      <li><a href="https://arxiv.org/abs/1610.07584">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#thomas-funkhouser-data-driven-methods-for-matching-labeling-and-synthesizing-3d-shapes">Data-Driven Methods for Matching, Labeling, and Synthesizing 3D Shapes</a>
</td>
      <td></td>
    </tr>

    <tr>
      <td>03/05</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#dileep-george-visual-perception-data-efficiency-and-deep-learning">Dileep George</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="http://science.sciencemag.org/content/early/2017/10/26/science.aag2612.full">A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs</a></li>
      <li><a href="https://arxiv.org/abs/1710.09829">Dynamic Routing Between Capsules</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="http://www.dam.brown.edu/people/geman/Homepage/Essays%20and%20ideas%20about%20neurobiology/bias-variance.pdf">Neural networks and the bias variance dilemma</a></li>
      <li><a href="http://www.cnbc.cmu.edu/~tai/papers/lee_mumford_josa.pdf">Hierarchical Bayesian inference in the visual cortex</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#dileep-george-visual-perception-data-efficiency-and-deep-learning">Visual Perception, Data Efficiency, and Deep Learning</a></td>
      <td></td>
    </tr>

    <tr>
      <td>03/12</td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#bruno-olshausen-perception-in-brains-and-machines">Bruno Olshausen</a></td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1611.09430">Emergence of foveal image sampling from learning to attend in visual scenes</a></li>
      <li><a href="https://arxiv.org/abs/1112.6209">Building High-level Features
Using Large Scale Unsupervised Learning</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://www.ece.rice.edu/~eld1/papers/Rozell08.pdf">Sparse Coding via Thresholding and Local Competition in Neural Circuits</a></li>
      </ul>
      </td>
      <td><a href="https://berkeley-deep-learning.github.io/cs294-131-s18/speakers.html#bruno-olshausen-perception-in-brains-and-machines">Perception in Brains and Machines</a></td>
      <td></td>
    </tr>

    <tr>
      <td>03/19</td>
      <td>Ian Goodfellow</td>
      <td>TBD
      </td>
      <td></td>
      <td>Final Project Milestone Due</td>
    </tr>

    <tr>
      <td>03/26</td>
      <td>Spring Break</td>
      <td>
      </td>
      <td></td>
      <td></td>
    </tr>

    <tr>
      <td>04/02</td>
      <td>Mohammad Norouzi</td>
      <td>TBD
      </td>
      <td></td>
      <td></td>
    </tr>

    <tr>
      <td>04/09</td>
      <td>Abhinav Gupta</td>
      <td>TBD
      </td>
      <td></td>
      <td></td>
    </tr>

    <tr>
      <td>04/16</td>
      <td>Ryan Adams</td>
      <td>TBD
      </td>
      <td></td>
      <td></td>
    </tr>

    <tr>
      <td>04/23</td>
      <td>POSTER SESSION</td>
      <td>
      </td>
      <td></td>
      <td></td>
    </tr>

    <tr>
      <td>04/27</td>
      <td></td>
      <td>
      </td>
      <td></td>
      <td>FINAL REPORT DUE</td>
    </tr>

Poster Session
  </tbody>
</table>

## Course description

In recent years, deep learning has enabled huge progress in many domains
including computer vision, speech, NLP, and robotics. It has become the leading
solution for many tasks, from winning the ImageNet competition to winning at Go
against a world champion. This class is designed to help students develop a
deeper understanding of deep learning and explore new research directions and
applications of deep learning. It assumes that students already have a basic
understanding of deep learning. In particular, we will explore a selected list
of new, cutting-edge topics in deep learning, including new techniques and
architectures in deep learning, security and privacy issues in deep learning,
recent advances in the theoretical and systems aspects of deep learning, and new
application domains of deep learning such as autonomous driving.

## Class format and project

This is a lecture, discussion, and project oriented class. Each lecture will
focus on one of the topics, including a survey of the state-of-the-art in the
area and an in-depth discussion of the topic. Each week, students are expected
to complete reading assignments before class and participate actively in class
discussion.

Students will also form project groups (two to three people per group) and
complete a research-quality class project.

## Enrollment information

**For undergraduates**: Please note that this is a graduate-level class.
However, with instructors' permission, we do allow qualified undergraduate
students to be in the class. If you are an undergraduate student and would like
to enroll in the class, please fill out
[**this form**](https://goo.gl/forms/akShIRmDLmmlaiu92)
and come to the first lecture of the class. Qualified undergraduates will be
given instructor codes to be allowed to register for the class after the first
lecture of the class, subject to space availability.

If you have not received grades for some classes that you are currently enrolled
in, please choose **Currently Enrolled** and then update the form when you
receive your final grades. You may also be interested in [this
class](https://people.eecs.berkeley.edu/~jfc/DeepLearn.html), which is open to
undergraduates.

Students may enroll in this class for variable units.

* **1 unit:** Participate in reading assignments (including serving as discussion lead once).
* **3 units:** Both reading assignments and a project. Projects may fall into one of
  four categories:
  * Traditional Literature Review of a deep learning topic (e.g., literature review of deep dialogue systems)
  * Distill-like Literature Review of a deep learning topic (e.g., a Distill-like blog post illustrating different optimization techniques used in deep learning)
  * Reimplement research code and open source it
  * Conference level research project
* You **may not** take this class for **4 units**.

## Deadlines

* Reading assignment deadlines:
  * For students,
    * Submit questions by Friday noon
    * Vote on the poll of discussion questions by Saturday 11:59 pm
  * For discussion leads,
    * Send form to collect questions from students by Wednesday 11:59 pm
    * Summarize questions proposed by students to form the poll and send it by Friday 11:59 pm
    * Summarize the poll to generate a ranked & categorized discussion question list and send the list to teaching staff by Sunday 7pm
    * Answer all Piazza questions about the assigned readings, both the week
    before and the week after the lecture.

## Grading
* 20% class participation
* 25% weekly reading assignment
  * 10% discussion leads
  * 15% individual reading assignments
* 55% project

## Additional Notes
* For students who need computing resources for the class project, we recommend you to look into AWS educate program for students. You'll get 100 dollar's worth of sign up credit. Here's the <a href="https://aws.amazon.com/education/awseducate/apply/"> link </a>.
